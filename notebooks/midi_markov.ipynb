{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85399f8e-4a59-4301-8bf7-013fd09a3f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:26.536857Z",
     "iopub.status.busy": "2025-06-27T05:38:26.536345Z",
     "iopub.status.idle": "2025-06-27T05:38:26.593793Z",
     "shell.execute_reply": "2025-06-27T05:38:26.593379Z",
     "shell.execute_reply.started": "2025-06-27T05:38:26.536816Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Optional, Tuple, Iterator\n",
    "from enum import Enum\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import defaultdict, deque\n",
    "import mido\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Core Domain Entities\n",
    "\n",
    "@dataclass\n",
    "class Note:\n",
    "    \"\"\"Represents a musical note with timing information\"\"\"\n",
    "    pitch: int  # MIDI note number (0-127)\n",
    "    velocity: int  # Note velocity (0-127)\n",
    "    start_time: float  # Absolute time when note starts\n",
    "    duration: float  # How long the note plays\n",
    "    channel: int = 0\n",
    "\n",
    "@dataclass\n",
    "class Rest:\n",
    "    \"\"\"Represents silence between notes\"\"\"\n",
    "    start_time: float\n",
    "    duration: float\n",
    "\n",
    "@dataclass\n",
    "class Track:\n",
    "    \"\"\"A sequence of musical events in a single track\"\"\"\n",
    "    name: str\n",
    "    notes: List[Note] = field(default_factory=list)\n",
    "    rests: List[Rest] = field(default_factory=list)\n",
    "    ticks_per_beat: int = 480\n",
    "    tempo: int = 500000  # microseconds per beat\n",
    "\n",
    "@dataclass\n",
    "class TransitionTable:\n",
    "    \"\"\"Markov chain transition probabilities\"\"\"\n",
    "    transitions: Dict[str, Dict[str, float]] = field(default_factory=dict)\n",
    "    kemeny_constant: Optional[float] = None\n",
    "    entropy: Optional[float] = None\n",
    "\n",
    "# MIDI Analysis Classes\n",
    "\n",
    "class MidiEventExtractor:\n",
    "    \"\"\"Extracts musical events from MIDI data\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.active_notes: Dict[int, float] = {}  # note -> start_time\n",
    "        self.last_event_time = 0.0\n",
    "        \n",
    "    def extract_track(self, midi_track, ticks_per_beat: int = 480) -> Track:\n",
    "        \"\"\"Extract Notes and Rests from a MIDI track\"\"\"\n",
    "        track = Track(name=getattr(midi_track, 'name', 'Untitled'))\n",
    "        track.ticks_per_beat = ticks_per_beat\n",
    "        \n",
    "        current_time = 0.0\n",
    "        last_note_end = 0.0\n",
    "        \n",
    "        for message in midi_track:\n",
    "            current_time += self._ticks_to_seconds(message.time, ticks_per_beat)\n",
    "            \n",
    "            if message.type == 'note_on' and message.velocity > 0:\n",
    "                # Check for rest before this note\n",
    "                if current_time > last_note_end and len(track.notes) > 0:\n",
    "                    rest_duration = current_time - last_note_end\n",
    "                    track.rests.append(Rest(last_note_end, rest_duration))\n",
    "                \n",
    "                self.active_notes[message.note] = current_time\n",
    "                \n",
    "            elif message.type in ['note_off', 'note_on'] and message.velocity == 0:\n",
    "                if message.note in self.active_notes:\n",
    "                    start_time = self.active_notes.pop(message.note)\n",
    "                    duration = current_time - start_time\n",
    "                    \n",
    "                    note = Note(\n",
    "                        pitch=message.note,\n",
    "                        velocity=getattr(message, 'velocity', 64),\n",
    "                        start_time=start_time,\n",
    "                        duration=duration,\n",
    "                        channel=message.channel\n",
    "                    )\n",
    "                    track.notes.append(note)\n",
    "                    last_note_end = max(last_note_end, current_time)\n",
    "        \n",
    "        return track\n",
    "    \n",
    "    def _ticks_to_seconds(self, ticks: int, ticks_per_beat: int, \n",
    "                         tempo: int = 500000) -> float:\n",
    "        \"\"\"Convert MIDI ticks to seconds\"\"\"\n",
    "        return (ticks / ticks_per_beat) * (tempo / 1_000_000)\n",
    "\n",
    "class MarkovChainBuilder:\n",
    "    \"\"\"Builds Markov chains from musical sequences\"\"\"\n",
    "    \n",
    "    def build_note_chain(self, notes: List[Note]) -> TransitionTable:\n",
    "        \"\"\"Build transition table for note sequences\"\"\"\n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        \n",
    "        for i in range(len(notes) - 1):\n",
    "            current = str(notes[i].pitch)\n",
    "            next_note = str(notes[i + 1].pitch)\n",
    "            transitions[current][next_note] += 1\n",
    "        \n",
    "        # Convert counts to probabilities\n",
    "        return self._normalize_transitions(transitions)\n",
    "    \n",
    "    def build_duration_chain(self, durations: List[float]) -> TransitionTable:\n",
    "        \"\"\"Build transition table for note/rest durations\"\"\"\n",
    "        # Quantize durations to make them discrete\n",
    "        quantized = [self._quantize_duration(d) for d in durations]\n",
    "        \n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        for i in range(len(quantized) - 1):\n",
    "            current = str(quantized[i])\n",
    "            next_dur = str(quantized[i + 1])\n",
    "            transitions[current][next_dur] += 1\n",
    "            \n",
    "        return self._normalize_transitions(transitions)\n",
    "    \n",
    "    def build_content_chain(self, track: Track) -> TransitionTable:\n",
    "        \"\"\"Build chain including both notes and rests\"\"\"\n",
    "        # Merge notes and rests into chronological sequence\n",
    "        events = []\n",
    "        for note in track.notes:\n",
    "            events.append(('note', str(note.pitch), note.start_time))\n",
    "        for rest in track.rests:\n",
    "            events.append(('rest', 'rest', rest.start_time))\n",
    "        \n",
    "        # Sort by time\n",
    "        events.sort(key=lambda x: x[2])\n",
    "        \n",
    "        transitions = defaultdict(lambda: defaultdict(int))\n",
    "        for i in range(len(events) - 1):\n",
    "            current = events[i][1]  # note pitch or 'rest'\n",
    "            next_event = events[i + 1][1]\n",
    "            transitions[current][next_event] += 1\n",
    "            \n",
    "        return self._normalize_transitions(transitions)\n",
    "    \n",
    "    def _quantize_duration(self, duration: float, \n",
    "                          quantization: float = 0.1) -> float:\n",
    "        \"\"\"Quantize duration to discrete values\"\"\"\n",
    "        return round(duration / quantization) * quantization\n",
    "    \n",
    "    def _normalize_transitions(self, transitions: Dict) -> TransitionTable:\n",
    "        \"\"\"Convert transition counts to probabilities\"\"\"\n",
    "        table = TransitionTable()\n",
    "        \n",
    "        for state, next_states in transitions.items():\n",
    "            total = sum(next_states.values())\n",
    "            table.transitions[state] = {\n",
    "                next_state: count / total \n",
    "                for next_state, count in next_states.items()\n",
    "            }\n",
    "        \n",
    "        # Calculate Kemeny constant and entropy\n",
    "        table.kemeny_constant = self._calculate_kemeny_constant(table)\n",
    "        table.entropy = self._calculate_entropy(table)\n",
    "        \n",
    "        return table\n",
    "    \n",
    "    def _calculate_kemeny_constant(self, table: TransitionTable) -> float:\n",
    "        \"\"\"Calculate Kemeny constant (simplified version)\"\"\"\n",
    "        # This is a placeholder - full calculation requires matrix operations\n",
    "        return len(table.transitions)\n",
    "    \n",
    "    def _calculate_entropy(self, table: TransitionTable) -> float:\n",
    "        \"\"\"Calculate Shannon entropy of transition table\"\"\"\n",
    "        total_entropy = 0.0\n",
    "        for state, transitions in table.transitions.items():\n",
    "            state_entropy = 0.0\n",
    "            for prob in transitions.values():\n",
    "                if prob > 0:\n",
    "                    state_entropy -= prob * np.log2(prob)\n",
    "            total_entropy += state_entropy\n",
    "        return total_entropy / len(table.transitions) if table.transitions else 0.0\n",
    "\n",
    "class EntropyAnalyzer:\n",
    "    \"\"\"Analyzes entropy in sliding windows\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: int = 10):\n",
    "        self.window_size = window_size\n",
    "    \n",
    "    def analyze_track_entropy(self, track: Track) -> List[Tuple[float, float]]:\n",
    "        \"\"\"Returns list of (entropy, timestamp) pairs\"\"\"\n",
    "        # Create sequence of events with timestamps\n",
    "        events = []\n",
    "        for note in track.notes:\n",
    "            events.append((str(note.pitch), note.start_time))\n",
    "        for rest in track.rests:\n",
    "            events.append(('rest', rest.start_time))\n",
    "        \n",
    "        events.sort(key=lambda x: x[1])  # Sort by time\n",
    "        \n",
    "        entropies = []\n",
    "        for i in range(len(events) - self.window_size + 1):\n",
    "            window_events = [e[0] for e in events[i:i + self.window_size]]\n",
    "            entropy = self._calculate_window_entropy(window_events)\n",
    "            timestamp = events[i][1]\n",
    "            entropies.append((entropy, timestamp))\n",
    "        \n",
    "        return entropies\n",
    "    \n",
    "    def _calculate_window_entropy(self, events: List[str]) -> float:\n",
    "        \"\"\"Calculate entropy for a window of events\"\"\"\n",
    "        from collections import Counter\n",
    "        counts = Counter(events)\n",
    "        total = len(events)\n",
    "        \n",
    "        entropy = 0.0\n",
    "        for count in counts.values():\n",
    "            prob = count / total\n",
    "            entropy -= prob * np.log2(prob)\n",
    "        \n",
    "        return entropy\n",
    "\n",
    "\n",
    "\n",
    "class MidiComposer:\n",
    "    \"\"\"Generates new MIDI compositions from Markov chains\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rng = np.random.default_rng()\n",
    "    \n",
    "    def generate_multi_track_composition(self, generator, length: int = 100) -> List[Track]:\n",
    "        \"\"\"Generate composition with all learned tracks\"\"\"\n",
    "        compositions = []\n",
    "        \n",
    "        for track_name in generator.note_chains.keys():\n",
    "            if track_name in generator.duration_chains and track_name in generator.content_chains:\n",
    "                print(f\"🎵 Generating track: {track_name}\")\n",
    "                \n",
    "                track = self.generate_track(\n",
    "                    generator.note_chains[track_name],\n",
    "                    generator.duration_chains[track_name], \n",
    "                    generator.content_chains[track_name],\n",
    "                    length\n",
    "                )\n",
    "                track.name = f\"Generated_{track_name}\"\n",
    "                compositions.append(track)\n",
    "        \n",
    "        return compositions\n",
    "    \n",
    "    def generate_track(self, note_chain: TransitionTable, \n",
    "                      duration_chain: TransitionTable,\n",
    "                      content_chain: TransitionTable,\n",
    "                      length: int = 100) -> Track:\n",
    "        \"\"\"Generate a single track with proper duration variety\"\"\"\n",
    "        track = Track(name=\"Generated\")\n",
    "        current_time = 0.0\n",
    "        \n",
    "        # Start with most common states\n",
    "        current_note = self._get_most_common_state(note_chain)\n",
    "        current_duration = self._get_most_common_state(duration_chain) \n",
    "        current_rest_duration = \"0.1\"  # Default rest\n",
    "        \n",
    "        print(f\"🎼 Starting composition with note {current_note}, duration {current_duration}\")\n",
    "        \n",
    "        for i in range(length):\n",
    "            # Decide if this should be a note or rest based on content chain\n",
    "            content_choice = self._sample_from_chain(content_chain, current_note)\n",
    "            \n",
    "            if content_choice != 'rest' and current_note != 'rest':\n",
    "                # Generate a note\n",
    "                try:\n",
    "                    duration = float(current_duration)\n",
    "                    note = Note(\n",
    "                        pitch=int(current_note),\n",
    "                        velocity=self.rng.integers(60, 100),  # Vary velocity too\n",
    "                        start_time=current_time,\n",
    "                        duration=duration\n",
    "                    )\n",
    "                    track.notes.append(note)\n",
    "                    current_time += duration\n",
    "                    \n",
    "                    # Get next note and duration\n",
    "                    current_note = self._sample_from_chain(note_chain, current_note)\n",
    "                    current_duration = self._sample_from_chain(duration_chain, current_duration)\n",
    "                    \n",
    "                except (ValueError, KeyError) as e:\n",
    "                    print(f\"⚠️  Skipping invalid note/duration: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            else:\n",
    "                # Generate a rest\n",
    "                try:\n",
    "                    rest_duration = float(current_rest_duration)\n",
    "                    if rest_duration > 0:\n",
    "                        rest = Rest(start_time=current_time, duration=rest_duration)\n",
    "                        track.rests.append(rest)\n",
    "                        current_time += rest_duration\n",
    "                    \n",
    "                    # Get next rest duration and note\n",
    "                    current_rest_duration = self._sample_from_chain(duration_chain, current_rest_duration)\n",
    "                    current_note = self._sample_from_chain(content_chain, 'rest')\n",
    "                    \n",
    "                except (ValueError, KeyError) as e:\n",
    "                    print(f\"⚠️  Skipping invalid rest: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"✅ Generated track with {len(track.notes)} notes and {len(track.rests)} rests\")\n",
    "        print(f\"📊 Duration range: {min([n.duration for n in track.notes]) if track.notes else 0:.2f} - {max([n.duration for n in track.notes]) if track.notes else 0:.2f}\")\n",
    "        \n",
    "        return track\n",
    "    \n",
    "    def _get_most_common_state(self, chain: TransitionTable) -> str:\n",
    "        \"\"\"Get the most probable starting state\"\"\"\n",
    "        if not chain.transitions:\n",
    "            return \"60\"  # Middle C fallback\n",
    "        \n",
    "        # Find state with most outgoing transitions (most connected)\n",
    "        best_state = max(chain.transitions.keys(), \n",
    "                        key=lambda k: len(chain.transitions[k]))\n",
    "        return best_state\n",
    "    \n",
    "    def _sample_from_chain(self, chain: TransitionTable, \n",
    "                          current_state: str) -> str:\n",
    "        \"\"\"Sample next state from transition probabilities\"\"\"\n",
    "        if current_state not in chain.transitions:\n",
    "            # Fallback to most common state\n",
    "            return self._get_most_common_state(chain)\n",
    "        \n",
    "        transitions = chain.transitions[current_state]\n",
    "        if not transitions:\n",
    "            return current_state\n",
    "        \n",
    "        states = list(transitions.keys())\n",
    "        probabilities = list(transitions.values())\n",
    "        \n",
    "        # Normalize probabilities (just in case)\n",
    "        prob_sum = sum(probabilities)\n",
    "        if prob_sum > 0:\n",
    "            probabilities = [p / prob_sum for p in probabilities]\n",
    "        else:\n",
    "            # Equal probability fallback\n",
    "            probabilities = [1.0 / len(states)] * len(states)\n",
    "        \n",
    "        return self.rng.choice(states, p=probabilities)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MidiInterface:\n",
    "    \"\"\"Handles MIDI I/O operations\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_port: Optional[mido.ports.BaseInput] = None\n",
    "        self.output_port: Optional[mido.ports.BaseOutput] = None\n",
    "    \n",
    "    def list_ports(self) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"List available MIDI input and output ports\"\"\"\n",
    "        return mido.get_input_names(), mido.get_output_names()\n",
    "    \n",
    "    def open_ports(self, input_name: Optional[str] = None, \n",
    "                   output_name: Optional[str] = None):\n",
    "        \"\"\"Open MIDI ports for I/O\"\"\"\n",
    "        try:\n",
    "            if input_name:\n",
    "                self.input_port = mido.open_input(input_name)\n",
    "            if output_name:\n",
    "                self.output_port = mido.open_output(output_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to open MIDI ports: {e}\")\n",
    "    \n",
    "    def load_midi_file(self, filepath: Path) -> List[Track]:\n",
    "        \"\"\"Load MIDI file and extract tracks\"\"\"\n",
    "        midi_file = mido.MidiFile(filepath)\n",
    "        extractor = MidiEventExtractor()\n",
    "        \n",
    "        tracks = []\n",
    "        for midi_track in midi_file.tracks:\n",
    "            track = extractor.extract_track(midi_track, midi_file.ticks_per_beat)\n",
    "            if track.notes:  # Only include tracks with notes\n",
    "                tracks.append(track)\n",
    "        \n",
    "        return tracks\n",
    "    \n",
    "    def save_track_to_midi(self, track: Track, filepath: Path):\n",
    "        \"\"\"Save a Track object to MIDI file\"\"\"\n",
    "        midi_file = mido.MidiFile(ticks_per_beat=track.ticks_per_beat)\n",
    "        midi_track = mido.MidiTrack()\n",
    "        midi_file.tracks.append(midi_track)\n",
    "        \n",
    "        # Convert Track back to MIDI messages\n",
    "        events = []\n",
    "        \n",
    "        # Add note events\n",
    "        for note in track.notes:\n",
    "            events.append((note.start_time, 'note_on', note))\n",
    "            events.append((note.start_time + note.duration, 'note_off', note))\n",
    "        \n",
    "        # Sort by time\n",
    "        events.sort(key=lambda x: x[0])\n",
    "        \n",
    "        current_time = 0.0\n",
    "        for event_time, event_type, note in events:\n",
    "            delta_time = int((event_time - current_time) * track.ticks_per_beat)\n",
    "            current_time = event_time\n",
    "            \n",
    "            if event_type == 'note_on':\n",
    "                msg = mido.Message('note_on', channel=note.channel,\n",
    "                                 note=note.pitch, velocity=note.velocity,\n",
    "                                 time=delta_time)\n",
    "            else:\n",
    "                msg = mido.Message('note_off', channel=note.channel,\n",
    "                                 note=note.pitch, velocity=0,\n",
    "                                 time=delta_time)\n",
    "            \n",
    "            midi_track.append(msg)\n",
    "        \n",
    "        midi_file.save(filepath)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main Application Class\n",
    "\n",
    "class MarkovMidiGenerator:\n",
    "    \"\"\"Main application orchestrating all components\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.midi_interface = MidiInterface()\n",
    "        self.chain_builder = MarkovChainBuilder()\n",
    "        self.entropy_analyzer = EntropyAnalyzer()\n",
    "        self.composer = MidiComposer()\n",
    "        \n",
    "        # Storage for learned patterns\n",
    "        self.tracks: List[Track] = []\n",
    "        self.note_chains: Dict[str, TransitionTable] = {}\n",
    "        self.duration_chains: Dict[str, TransitionTable] = {}\n",
    "        self.content_chains: Dict[str, TransitionTable] = {}\n",
    "    \n",
    "    def analyze_midi_file(self, filepath: Path) -> Dict[str, any]:\n",
    "        \"\"\"Analyze a MIDI file and build all Markov chains\"\"\"\n",
    "        self.tracks = self.midi_interface.load_midi_file(filepath)\n",
    "        \n",
    "        results = {}\n",
    "        for i, track in enumerate(self.tracks):\n",
    "            track_name = f\"track_{i}\"\n",
    "            \n",
    "            # Build chains\n",
    "            note_chain = self.chain_builder.build_note_chain(track.notes)\n",
    "            duration_chain = self.chain_builder.build_duration_chain(\n",
    "                [n.duration for n in track.notes]\n",
    "            )\n",
    "            content_chain = self.chain_builder.build_content_chain(track)\n",
    "            \n",
    "            # Store chains\n",
    "            self.note_chains[track_name] = note_chain\n",
    "            self.duration_chains[track_name] = duration_chain\n",
    "            self.content_chains[track_name] = content_chain\n",
    "            \n",
    "            # Analyze entropy\n",
    "            entropy_analysis = self.entropy_analyzer.analyze_track_entropy(track)\n",
    "            \n",
    "            results[track_name] = {\n",
    "                'notes': len(track.notes),\n",
    "                'rests': len(track.rests),\n",
    "                'kemeny_constant': note_chain.kemeny_constant,\n",
    "                'entropy': note_chain.entropy,\n",
    "                'entropy_timeline': entropy_analysis\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def generate_composition(self, track_name: str, length: int = 100) -> Track:\n",
    "        \"\"\"Generate new composition based on learned patterns\"\"\"\n",
    "        if track_name not in self.note_chains:\n",
    "            raise ValueError(f\"No learned patterns for track: {track_name}\")\n",
    "        \n",
    "        note_chain = self.note_chains[track_name]\n",
    "        duration_chain = self.duration_chains[track_name]\n",
    "        content_chain = self.content_chains[track_name]\n",
    "        \n",
    "        # Use content chain for rest patterns\n",
    "        return self.composer.generate_track(\n",
    "            note_chain, duration_chain, content_chain, length\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def save_single_track_with_sustaining_instrument(self, track: Track, filepath: Path, instrument_choice: str = \"strings\"):\n",
    "        \"\"\"Save single track with a sustaining instrument that shows note duration clearly\"\"\"\n",
    "        import mido\n",
    "        \n",
    "        midi_file = mido.MidiFile(type=0, ticks_per_beat=480)  # Type 0 = single track\n",
    "        midi_track = mido.MidiTrack()\n",
    "        midi_file.tracks.append(midi_track)\n",
    "        \n",
    "        # Choose sustaining instruments based on preference\n",
    "        instrument_options = {\n",
    "            \"strings\": (40, \"Violin\"),           # Clear and expressive\n",
    "            \"cello\": (42, \"Cello\"),             # Rich and warm\n",
    "            \"flute\": (73, \"Flute\"),             # Pure and clear\n",
    "            \"clarinet\": (71, \"Clarinet\"),       # Warm woodwind\n",
    "            \"trumpet\": (56, \"Trumpet\"),         # Bright brass\n",
    "            \"french_horn\": (60, \"French Horn\"), # Noble brass\n",
    "            \"organ\": (19, \"Church Organ\"),      # Perfect for your background!\n",
    "            \"synth_pad\": (88, \"New Age Pad\"),   # Modern sustain\n",
    "        }\n",
    "        \n",
    "        if instrument_choice not in instrument_options:\n",
    "            instrument_choice = \"strings\"  # Default fallback\n",
    "        \n",
    "        instrument_num, instrument_name = instrument_options[instrument_choice]\n",
    "        \n",
    "        # Set track name\n",
    "        track_name = f\"{instrument_name}: {track.name}\"\n",
    "        midi_track.append(mido.MetaMessage('track_name', name=track_name, time=0))\n",
    "        \n",
    "        # Set instrument\n",
    "        midi_track.append(mido.Message('program_change', channel=0, program=instrument_num, time=0))\n",
    "        \n",
    "        # Add musical settings\n",
    "        midi_track.append(mido.Message('control_change', channel=0, control=7, value=100, time=0))  # Volume\n",
    "        midi_track.append(mido.Message('control_change', channel=0, control=91, value=50, time=0))  # Reverb\n",
    "        \n",
    "        print(f\"🎵 Saving single track with {instrument_name}\")\n",
    "        \n",
    "        # Convert track to MIDI events\n",
    "        events = []\n",
    "        for note in track.notes:\n",
    "            events.append((note.start_time, 'note_on', note))\n",
    "            events.append((note.start_time + note.duration, 'note_off', note))\n",
    "        \n",
    "        # Sort by time\n",
    "        events.sort(key=lambda x: x[0])\n",
    "        \n",
    "        current_time = 0.0\n",
    "        for event_time, event_type, note in events:\n",
    "            delta_ticks = int((event_time - current_time) * 480)\n",
    "            current_time = event_time\n",
    "            \n",
    "            if event_type == 'note_on':\n",
    "                msg = mido.Message('note_on', channel=0, note=note.pitch, \n",
    "                                 velocity=note.velocity, time=delta_ticks)\n",
    "            else:\n",
    "                msg = mido.Message('note_off', channel=0, note=note.pitch, \n",
    "                                 velocity=0, time=delta_ticks)\n",
    "            \n",
    "            midi_track.append(msg)\n",
    "        \n",
    "        # End of track\n",
    "        midi_track.append(mido.MetaMessage('end_of_track', time=0))\n",
    "        \n",
    "        midi_file.save(filepath)\n",
    "        print(f\"💾 Saved single track ({instrument_name}) to {filepath}\")\n",
    "    \n",
    "    # Convenience method for single track generation with better instruments\n",
    "    def generate_single_track_with_sustaining_instrument(self, track_name: str, length: int = 50, instrument: str = \"strings\"):\n",
    "        \"\"\"Generate and save single track with sustaining instrument\"\"\"\n",
    "        \n",
    "        # Generate single track\n",
    "        single_track = self.generate_composition(track_name, length)\n",
    "        \n",
    "        # Save with sustaining instrument\n",
    "        output_path = Path(f\"/Users/abraxas3d/organ_donor/data/generated/single_track_{instrument}_{track_name}.mid\")\n",
    "        self.save_single_track_with_sustaining_instrument(single_track, output_path, instrument)\n",
    "        \n",
    "        print(f\"📊 Generated single track: {len(single_track.notes)} notes, {len(single_track.rests)} rests\")\n",
    "        \n",
    "        return output_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def generate_multi_track_composition(self, length: int = 100) -> List[Track]:\n",
    "        \"\"\"Generate composition with all learned tracks\"\"\"\n",
    "        return self.composer.generate_multi_track_composition(self, length)\n",
    "    \n",
    "    def save_multi_track_composition(self, tracks: List[Track], filepath: Path):\n",
    "        \"\"\"Save multiple tracks to a single MIDI file\"\"\"\n",
    "        import mido\n",
    "        \n",
    "        midi_file = mido.MidiFile(ticks_per_beat=480)\n",
    "        \n",
    "        for track in tracks:\n",
    "            midi_track = mido.MidiTrack()\n",
    "            midi_track.name = track.name\n",
    "            midi_file.tracks.append(midi_track)\n",
    "            \n",
    "            # Convert Track to MIDI messages\n",
    "            events = []\n",
    "            \n",
    "            # Add note events\n",
    "            for note in track.notes:\n",
    "                events.append((note.start_time, 'note_on', note))\n",
    "                events.append((note.start_time + note.duration, 'note_off', note))\n",
    "            \n",
    "            # Sort by time\n",
    "            events.sort(key=lambda x: x[0])\n",
    "            \n",
    "            current_time = 0.0\n",
    "            for event_time, event_type, note in events:\n",
    "                delta_time = int((event_time - current_time) * 480)  # Convert to ticks\n",
    "                current_time = event_time\n",
    "                \n",
    "                if event_type == 'note_on':\n",
    "                    msg = mido.Message('note_on', channel=note.channel,\n",
    "                                     note=note.pitch, velocity=note.velocity,\n",
    "                                     time=delta_time)\n",
    "                else:\n",
    "                    msg = mido.Message('note_off', channel=note.channel,\n",
    "                                     note=note.pitch, velocity=0,\n",
    "                                     time=delta_time)\n",
    "                \n",
    "                midi_track.append(msg)\n",
    "        \n",
    "        midi_file.save(filepath)\n",
    "        print(f\"💾 Saved {len(tracks)} tracks to {filepath}\")\n",
    "\n",
    "\n",
    "\n",
    "    def save_multi_track_composition_with_sustaining_instruments(self, tracks: List[Track], filepath: Path):\n",
    "        \"\"\"Save multiple tracks with instruments that showcase duration and musical patterns\"\"\"\n",
    "        import mido\n",
    "        \n",
    "        midi_file = mido.MidiFile(type=1, ticks_per_beat=480)\n",
    "        \n",
    "        # Sustaining instruments perfect for hearing note duration\n",
    "        instrument_families = {\n",
    "            0: (\"Strings\", [40, 41, 42, 43]),           # Violin, Viola, Cello, Bass\n",
    "            1: (\"Woodwinds\", [73, 74, 71, 68]),        # Flute, Recorder, Clarinet, Oboe\n",
    "            2: (\"Brass\", [56, 57, 60, 58]),            # Trumpet, Trombone, French Horn, Tuba\n",
    "            3: (\"Organs\", [16, 17, 18, 19]),           # Various organ sounds\n",
    "            4: (\"Synth Pads\", [88, 89, 90, 91]),       # Sustained synths\n",
    "        }\n",
    "        \n",
    "        for i, track in enumerate(tracks):\n",
    "            midi_track = mido.MidiTrack()\n",
    "            \n",
    "            # Choose instrument family and specific instrument\n",
    "            family_idx = i % len(instrument_families)\n",
    "            family_name, family_instruments = list(instrument_families.values())[family_idx]\n",
    "            instrument = family_instruments[i % len(family_instruments)]\n",
    "            \n",
    "            # Create descriptive track name\n",
    "            track_name = f\"{family_name} {i+1}: {track.name}\"\n",
    "            midi_track.append(mido.MetaMessage('track_name', name=track_name, time=0))\n",
    "            \n",
    "            # Set unique channel\n",
    "            channel = i % 16\n",
    "            \n",
    "            # Set instrument\n",
    "            midi_track.append(mido.Message('program_change', channel=channel, program=instrument, time=0))\n",
    "            \n",
    "            # Add musical expression\n",
    "            midi_track.append(mido.Message('control_change', channel=channel, control=7, value=100, time=0))  # Volume\n",
    "            midi_track.append(mido.Message('control_change', channel=channel, control=91, value=40, time=0))  # Reverb\n",
    "            \n",
    "            print(f\"🎺 Track {i+1}: {family_name}, Instrument {instrument}, Channel {channel}\")\n",
    "            \n",
    "            # Convert notes to MIDI events\n",
    "            events = []\n",
    "            for note in track.notes:\n",
    "                # Add slight velocity variation for musical expression\n",
    "                musical_velocity = max(40, min(127, note.velocity + np.random.randint(-20, 20)))\n",
    "                events.append((note.start_time, 'note_on', note, channel, musical_velocity))\n",
    "                events.append((note.start_time + note.duration, 'note_off', note, channel))\n",
    "            \n",
    "            events.sort(key=lambda x: x[0])\n",
    "            \n",
    "            current_time = 0.0\n",
    "            for event_time, event_type, note, ch, *velocity in events:\n",
    "                delta_ticks = int((event_time - current_time) * 480)\n",
    "                current_time = event_time\n",
    "                \n",
    "                if event_type == 'note_on':\n",
    "                    vel = velocity[0] if velocity else note.velocity\n",
    "                    msg = mido.Message('note_on', channel=ch, note=note.pitch, \n",
    "                                     velocity=vel, time=delta_ticks)\n",
    "                else:\n",
    "                    msg = mido.Message('note_off', channel=ch, note=note.pitch, \n",
    "                                     velocity=0, time=delta_ticks)\n",
    "                \n",
    "                midi_track.append(msg)\n",
    "            \n",
    "            # End of track\n",
    "            midi_track.append(mido.MetaMessage('end_of_track', time=0))\n",
    "            midi_file.tracks.append(midi_track)\n",
    "        \n",
    "        midi_file.save(filepath)\n",
    "        print(f\"🎼 Saved {len(tracks)} tracks with sustaining instruments to {filepath}\")\n",
    "        print(\"🎵 These instruments will make note durations and musical patterns much clearer!\")\n",
    "\n",
    "    def save_with_organ_stops(self, tracks: List[Track], filepath: Path):\n",
    "        \"\"\"Create composition using different organ stops - perfect for your pipe organ!\"\"\"\n",
    "        import mido\n",
    "        \n",
    "        midi_file = mido.MidiFile(type=1, ticks_per_beat=480)\n",
    "        \n",
    "        # Pipe organ stops\n",
    "        organ_stops = [\n",
    "            (19, \"Principal 8'\"),        # Church Organ - foundation stop\n",
    "            (16, \"Flute 8'\"),           # Drawbar Organ - flute-like \n",
    "            (17, \"Reed 8'\"),            # Percussive Organ - reed stop\n",
    "            (18, \"Mixture\"),            # Rock Organ - bright mixture\n",
    "            (20, \"Reed Organ\"),         # Reed Organ - different reed\n",
    "            (88, \"String 8'\"),          # Pad - string-like stop\n",
    "            (89, \"Bourdon 16'\"),        # Warm Pad - soft foundation\n",
    "        ]\n",
    "        \n",
    "        for i, track in enumerate(tracks):\n",
    "            midi_track = mido.MidiTrack()\n",
    "            \n",
    "            # Select organ stop\n",
    "            instrument_num, stop_name = organ_stops[i % len(organ_stops)]\n",
    "            \n",
    "            track_name = f\"Organ {stop_name}: {track.name}\"\n",
    "            midi_track.append(mido.MetaMessage('track_name', name=track_name, time=0))\n",
    "            \n",
    "            channel = i % 16\n",
    "            midi_track.append(mido.Message('program_change', channel=channel, program=instrument_num, time=0))\n",
    "            \n",
    "            # Organ-specific MIDI settings\n",
    "            midi_track.append(mido.Message('control_change', channel=channel, control=7, value=110, time=0))  # Volume\n",
    "            midi_track.append(mido.Message('control_change', channel=channel, control=91, value=60, time=0))  # Reverb\n",
    "            \n",
    "            print(f\"🏛️  Track {i+1}: {stop_name}, Channel {channel}\")\n",
    "            \n",
    "            # Add notes\n",
    "            events = []\n",
    "            for note in track.notes:\n",
    "                events.append((note.start_time, 'note_on', note, channel))\n",
    "                events.append((note.start_time + note.duration, 'note_off', note, channel))\n",
    "            \n",
    "            events.sort(key=lambda x: x[0])\n",
    "            \n",
    "            current_time = 0.0\n",
    "            for event_time, event_type, note, ch in events:\n",
    "                delta_ticks = int((event_time - current_time) * 480)\n",
    "                current_time = event_time\n",
    "                \n",
    "                if event_type == 'note_on':\n",
    "                    msg = mido.Message('note_on', channel=ch, note=note.pitch, \n",
    "                                     velocity=note.velocity, time=delta_ticks)\n",
    "                else:\n",
    "                    msg = mido.Message('note_off', channel=ch, note=note.pitch, \n",
    "                                     velocity=0, time=delta_ticks)\n",
    "                \n",
    "                midi_track.append(msg)\n",
    "            \n",
    "            midi_track.append(mido.MetaMessage('end_of_track', time=0))\n",
    "            midi_file.tracks.append(midi_track)\n",
    "        \n",
    "        midi_file.save(filepath)\n",
    "        print(f\"🎼 Saved organ composition with {len(tracks)} stops to {filepath}\")\n",
    "\n",
    "    def generate_and_save_with_better_instruments(self, length: int = 40):\n",
    "        \"\"\"Convenience method to generate and save with sustaining instruments\"\"\"\n",
    "        \n",
    "        # Generate composition\n",
    "        compositions = self.generate_multi_track_composition(length)\n",
    "        \n",
    "        # Save with sustaining instruments\n",
    "        sustaining_path = Path(\"data/generated/composition_sustaining.mid\")\n",
    "        sustaining_path.parent.mkdir(exist_ok=True)\n",
    "        self.save_multi_track_composition_with_sustaining_instruments(compositions, sustaining_path)\n",
    "        \n",
    "        # Save with organ stops\n",
    "        organ_path = Path(\"data/generated/composition_organ.mid\")\n",
    "        self.save_with_organ_stops(compositions, organ_path)\n",
    "        \n",
    "        print(f\"\\n🎵 Created two versions:\")\n",
    "        print(f\"1. Sustaining instruments: {sustaining_path}\")\n",
    "        print(f\"2. Organ stops: {organ_path}\")\n",
    "        \n",
    "        return sustaining_path, organ_path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def open_in_garageband(midi_path):\n",
    "        \"\"\"Open MIDI file in GarageBand (macOS)\"\"\"\n",
    "        try:\n",
    "            subprocess.run([\"open\", \"-a\", \"GarageBand\", str(midi_path)])\n",
    "            print(f\"🎵 Opening {midi_path.name} in GarageBand...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening GarageBand: {e}\")\n",
    "            # Fallback to default app\n",
    "            subprocess.run([\"open\", str(midi_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c24e627-500b-4616-90a4-5a344cf5861c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:27.020727Z",
     "iopub.status.busy": "2025-06-27T05:38:27.020075Z",
     "iopub.status.idle": "2025-06-27T05:38:27.724533Z",
     "shell.execute_reply": "2025-06-27T05:38:27.724213Z",
     "shell.execute_reply.started": "2025-06-27T05:38:27.020675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created note: Note(pitch=60, velocity=80, start_time=0.0, duration=1.0, channel=0)\n",
      "✅ Created track with 1 notes\n",
      "✅ Found 0 MIDI output ports\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test cell - add this to your notebook\n",
    "def test_basic_functionality():\n",
    "    \"\"\"Quick test of the main classes\"\"\"\n",
    "    \n",
    "    # Test creating a simple note\n",
    "    note = Note(pitch=60, velocity=80, start_time=0.0, duration=1.0)\n",
    "    print(f\"✅ Created note: {note}\")\n",
    "    \n",
    "    # Test creating a track\n",
    "    track = Track(name=\"Test Track\")\n",
    "    track.notes.append(note)\n",
    "    print(f\"✅ Created track with {len(track.notes)} notes\")\n",
    "    \n",
    "    # Test MIDI interface\n",
    "    midi_interface = MidiInterface()\n",
    "    inputs, outputs = midi_interface.list_ports()\n",
    "    print(f\"✅ Found {len(outputs)} MIDI output ports\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run the test\n",
    "test_basic_functionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ccc54e4-227c-4cd2-9416-5b21dadba78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:27.725313Z",
     "iopub.status.busy": "2025-06-27T05:38:27.725222Z",
     "iopub.status.idle": "2025-06-27T05:38:27.727775Z",
     "shell.execute_reply": "2025-06-27T05:38:27.727507Z",
     "shell.execute_reply.started": "2025-06-27T05:38:27.725304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input ports: []\n",
      "Output ports: []\n"
     ]
    }
   ],
   "source": [
    "# Check for connected MIDI devices\n",
    "\n",
    "midi_interface = MidiInterface()\n",
    "inputs, outputs = midi_interface.list_ports()\n",
    "print(f\"Input ports: {inputs}\")\n",
    "print(f\"Output ports: {outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9322e2e-6134-4f85-b13f-7bbdc2f1741d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:28.246976Z",
     "iopub.status.busy": "2025-06-27T05:38:28.246398Z",
     "iopub.status.idle": "2025-06-27T05:38:28.357728Z",
     "shell.execute_reply": "2025-06-27T05:38:28.357472Z",
     "shell.execute_reply.started": "2025-06-27T05:38:28.246908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 17 notes and 83 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generated new single-track composition: /Users/abraxas3d/organ_donor/data/generated/bach_inspired_composition.mid\n",
      "📊 New single-track piece has 17 notes and 83 rests\n"
     ]
    }
   ],
   "source": [
    "# Test with actual MIDI data\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a simple test MIDI file or use one you have\n",
    "generator = MarkovMidiGenerator()\n",
    "\n",
    "# If you have a MIDI file, try:\n",
    "results = generator.analyze_midi_file(Path(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/beet.mid\"))\n",
    "#print(results)\n",
    "\n",
    "# Generate new composition based on learned patterns - single track\n",
    "track_name = list(results.keys())[0]  # Use first track's patterns\n",
    "new_composition = generator.generate_composition(track_name, length=100)\n",
    "\n",
    "# Save the new composition as MIDI\n",
    "output_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/bach_inspired_composition.mid\") \n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "generator.midi_interface.save_track_to_midi(new_composition, output_path)\n",
    "\n",
    "print(f\"🎵 Generated new single-track composition: {output_path}\")\n",
    "print(f\"📊 New single-track piece has {len(new_composition.notes)} notes and {len(new_composition.rests)} rests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f09feb2-c1e5-49b6-9701-a22de59c05b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:29.339629Z",
     "iopub.status.busy": "2025-06-27T05:38:29.338991Z",
     "iopub.status.idle": "2025-06-27T05:38:29.409138Z",
     "shell.execute_reply": "2025-06-27T05:38:29.408872Z",
     "shell.execute_reply.started": "2025-06-27T05:38:29.339584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 Generating track: track_0\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 23 notes and 77 rests\n",
      "📊 Duration range: 0.10 - 0.70\n",
      "🎵 Generating track: track_1\n",
      "🎼 Starting composition with note 76, duration 0.30000000000000004\n",
      "✅ Generated track with 29 notes and 71 rests\n",
      "📊 Duration range: 0.10 - 0.40\n",
      "🎵 Generating track: track_2\n",
      "🎼 Starting composition with note 76, duration 0.5\n",
      "✅ Generated track with 30 notes and 70 rests\n",
      "📊 Duration range: 0.50 - 2.00\n",
      "🎵 Generating track: track_3\n",
      "🎼 Starting composition with note 57, duration 0.5\n",
      "✅ Generated track with 21 notes and 79 rests\n",
      "📊 Duration range: 0.10 - 0.60\n",
      "🎵 Generating track: track_4\n",
      "🎼 Starting composition with note 64, duration 0.5\n",
      "✅ Generated track with 12 notes and 88 rests\n",
      "📊 Duration range: 0.10 - 0.60\n",
      "🎵 Generating track: track_5\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 25 notes and 75 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_6\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 0 notes and 100 rests\n",
      "📊 Duration range: 0.00 - 0.00\n",
      "🎵 Generating track: track_7\n",
      "🎼 Starting composition with note 69, duration 0.2\n",
      "✅ Generated track with 12 notes and 88 rests\n",
      "📊 Duration range: 0.20 - 0.50\n",
      "🎵 Generating track: track_8\n",
      "🎼 Starting composition with note 64, duration 0.5\n",
      "✅ Generated track with 21 notes and 79 rests\n",
      "📊 Duration range: 0.20 - 1.10\n",
      "🎵 Generating track: track_9\n",
      "🎼 Starting composition with note 55, duration 0.5\n",
      "✅ Generated track with 19 notes and 81 rests\n",
      "📊 Duration range: 0.10 - 4.00\n",
      "🎵 Generating track: track_10\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 0 notes and 100 rests\n",
      "📊 Duration range: 0.00 - 0.00\n",
      "🎵 Generating track: track_11\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 33 notes and 67 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "\n",
      "🎼 Generated 12 tracks:\n",
      "  Generated_track_0: 23 notes, duration variety: 7 unique durations\n",
      "    Duration range: 0.100 - 0.700\n",
      "  Generated_track_1: 29 notes, duration variety: 4 unique durations\n",
      "    Duration range: 0.100 - 0.400\n",
      "  Generated_track_2: 30 notes, duration variety: 4 unique durations\n",
      "    Duration range: 0.500 - 2.000\n",
      "  Generated_track_3: 21 notes, duration variety: 5 unique durations\n",
      "    Duration range: 0.100 - 0.600\n",
      "  Generated_track_4: 12 notes, duration variety: 5 unique durations\n",
      "    Duration range: 0.100 - 0.600\n",
      "  Generated_track_5: 25 notes, duration variety: 3 unique durations\n",
      "    Duration range: 0.100 - 0.500\n",
      "  Generated_track_6: 0 notes, duration variety: 0 unique durations\n",
      "  Generated_track_7: 12 notes, duration variety: 2 unique durations\n",
      "    Duration range: 0.200 - 0.500\n",
      "  Generated_track_8: 21 notes, duration variety: 7 unique durations\n",
      "    Duration range: 0.200 - 1.100\n",
      "  Generated_track_9: 19 notes, duration variety: 5 unique durations\n",
      "    Duration range: 0.100 - 4.000\n",
      "  Generated_track_10: 0 notes, duration variety: 0 unique durations\n",
      "  Generated_track_11: 33 notes, duration variety: 4 unique durations\n",
      "    Duration range: 0.100 - 0.500\n",
      "💾 Saved 12 tracks to /Users/abraxas3d/organ_donor/data/generated/bach_multi_track.mid\n"
     ]
    }
   ],
   "source": [
    "# Generate multiple tracks\n",
    "compositions = generator.generate_multi_track_composition(length=100)\n",
    "\n",
    "print(f\"\\n🎼 Generated {len(compositions)} tracks:\")\n",
    "for track in compositions:\n",
    "    note_durations = [n.duration for n in track.notes]\n",
    "    print(f\"  {track.name}: {len(track.notes)} notes, duration variety: {len(set(note_durations))} unique durations\")\n",
    "    if note_durations:\n",
    "        print(f\"    Duration range: {min(note_durations):.3f} - {max(note_durations):.3f}\")\n",
    "\n",
    "# Save multi-track composition\n",
    "multi_track_output_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/bach_multi_track.mid\")\n",
    "multi_track_output_path.parent.mkdir(exist_ok=True)\n",
    "generator.save_multi_track_composition(compositions, multi_track_output_path)\n",
    "\n",
    "\n",
    "# Open in GarageBand\n",
    "#open_in_garageband(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9dc1216-e0bf-4dcf-b90d-4150d9d0a119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:38:30.291476Z",
     "iopub.status.busy": "2025-06-27T05:38:30.290868Z",
     "iopub.status.idle": "2025-06-27T05:38:30.363547Z",
     "shell.execute_reply": "2025-06-27T05:38:30.363284Z",
     "shell.execute_reply.started": "2025-06-27T05:38:30.291433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎵 Generating track: track_0\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 19 notes and 81 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_1\n",
      "🎼 Starting composition with note 76, duration 0.30000000000000004\n",
      "✅ Generated track with 24 notes and 76 rests\n",
      "📊 Duration range: 0.10 - 2.00\n",
      "🎵 Generating track: track_2\n",
      "🎼 Starting composition with note 76, duration 0.5\n",
      "✅ Generated track with 29 notes and 71 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_3\n",
      "🎼 Starting composition with note 57, duration 0.5\n",
      "✅ Generated track with 28 notes and 72 rests\n",
      "📊 Duration range: 0.10 - 1.10\n",
      "🎵 Generating track: track_4\n",
      "🎼 Starting composition with note 64, duration 0.5\n",
      "✅ Generated track with 15 notes and 85 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_5\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 20 notes and 80 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_6\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 0 notes and 100 rests\n",
      "📊 Duration range: 0.00 - 0.00\n",
      "🎵 Generating track: track_7\n",
      "🎼 Starting composition with note 69, duration 0.2\n",
      "✅ Generated track with 13 notes and 87 rests\n",
      "📊 Duration range: 0.10 - 0.30\n",
      "🎵 Generating track: track_8\n",
      "🎼 Starting composition with note 64, duration 0.5\n",
      "✅ Generated track with 19 notes and 81 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎵 Generating track: track_9\n",
      "🎼 Starting composition with note 55, duration 0.5\n",
      "✅ Generated track with 8 notes and 92 rests\n",
      "📊 Duration range: 0.20 - 4.50\n",
      "🎵 Generating track: track_10\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 0 notes and 100 rests\n",
      "📊 Duration range: 0.00 - 0.00\n",
      "🎵 Generating track: track_11\n",
      "🎼 Starting composition with note 45, duration 0.1\n",
      "✅ Generated track with 30 notes and 70 rests\n",
      "📊 Duration range: 0.10 - 0.50\n",
      "🎺 Track 1: Strings, Instrument 40, Channel 0\n",
      "🎺 Track 2: Woodwinds, Instrument 74, Channel 1\n",
      "🎺 Track 3: Brass, Instrument 60, Channel 2\n",
      "🎺 Track 4: Organs, Instrument 19, Channel 3\n",
      "🎺 Track 5: Synth Pads, Instrument 88, Channel 4\n",
      "🎺 Track 6: Strings, Instrument 41, Channel 5\n",
      "🎺 Track 7: Woodwinds, Instrument 71, Channel 6\n",
      "🎺 Track 8: Brass, Instrument 58, Channel 7\n",
      "🎺 Track 9: Organs, Instrument 16, Channel 8\n",
      "🎺 Track 10: Synth Pads, Instrument 89, Channel 9\n",
      "🎺 Track 11: Strings, Instrument 42, Channel 10\n",
      "🎺 Track 12: Woodwinds, Instrument 68, Channel 11\n",
      "🎼 Saved 12 tracks with sustaining instruments to /Users/abraxas3d/organ_donor/data/generated/bach_clear_duration.mid\n",
      "🎵 These instruments will make note durations and musical patterns much clearer!\n",
      "🏛️  Track 1: Principal 8', Channel 0\n",
      "🏛️  Track 2: Flute 8', Channel 1\n",
      "🏛️  Track 3: Reed 8', Channel 2\n",
      "🏛️  Track 4: Mixture, Channel 3\n",
      "🏛️  Track 5: Reed Organ, Channel 4\n",
      "🏛️  Track 6: String 8', Channel 5\n",
      "🏛️  Track 7: Bourdon 16', Channel 6\n",
      "🏛️  Track 8: Principal 8', Channel 7\n",
      "🏛️  Track 9: Flute 8', Channel 8\n",
      "🏛️  Track 10: Reed 8', Channel 9\n",
      "🏛️  Track 11: Mixture, Channel 10\n",
      "🏛️  Track 12: Reed Organ, Channel 11\n",
      "🎼 Saved organ composition with 12 stops to /Users/abraxas3d/organ_donor/data/generated/bach_organ.mid\n"
     ]
    }
   ],
   "source": [
    "# Generate multiple tracks\n",
    "compositions = generator.generate_multi_track_composition(length=100)\n",
    "\n",
    "# Save with sustaining instruments  \n",
    "sustaining_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/bach_clear_duration.mid\")\n",
    "generator.save_multi_track_composition_with_sustaining_instruments(compositions, sustaining_path)\n",
    "\n",
    "# Save with organ stops\n",
    "organ_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/bach_organ.mid\") \n",
    "generator.save_with_organ_stops(compositions, organ_path)\n",
    "\n",
    "# Open in GarageBand\n",
    "#open_in_garageband(sustaining_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f628bce-fb12-4100-88ff-68516f212257",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:40:18.280178Z",
     "iopub.status.busy": "2025-06-27T05:40:18.279878Z",
     "iopub.status.idle": "2025-06-27T05:40:18.397077Z",
     "shell.execute_reply": "2025-06-27T05:40:18.396664Z",
     "shell.execute_reply.started": "2025-06-27T05:40:18.280162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tracks: ['track_0', 'track_1', 'track_2', 'track_3', 'track_4', 'track_5', 'track_6', 'track_7', 'track_8', 'track_9', 'track_10', 'track_11']\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 62 notes and 238 rests\n",
      "📊 Duration range: 0.10 - 1.00\n",
      "🎵 Saving single track with Violin\n",
      "💾 Saved single track (Violin) to /Users/abraxas3d/organ_donor/data/generated/single_track_strings_track_0.mid\n",
      "📊 Generated single track: 62 notes, 238 rests\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 70 notes and 230 rests\n",
      "📊 Duration range: 0.10 - 2.10\n",
      "🎵 Saving single track with Cello\n",
      "💾 Saved single track (Cello) to /Users/abraxas3d/organ_donor/data/generated/single_track_cello_track_0.mid\n",
      "📊 Generated single track: 70 notes, 230 rests\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 69 notes and 231 rests\n",
      "📊 Duration range: 0.10 - 0.80\n",
      "🎵 Saving single track with Flute\n",
      "💾 Saved single track (Flute) to /Users/abraxas3d/organ_donor/data/generated/single_track_flute_track_0.mid\n",
      "📊 Generated single track: 69 notes, 231 rests\n",
      "🎼 Starting composition with note 88, duration 0.30000000000000004\n",
      "✅ Generated track with 65 notes and 235 rests\n",
      "📊 Duration range: 0.10 - 2.10\n",
      "🎵 Saving single track with Church Organ\n",
      "💾 Saved single track (Church Organ) to /Users/abraxas3d/organ_donor/data/generated/single_track_organ_track_0.mid\n",
      "📊 Generated single track: 65 notes, 235 rests\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['open', '-a', 'GarageBand', '/Users/abraxas3d/organ_donor/data/generated/single_track_organ_track_0.mid'], returncode=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get available track names from your analysis\n",
    "available_tracks = list(generator.note_chains.keys())\n",
    "print(f\"Available tracks: {available_tracks}\")\n",
    "\n",
    "# Generate single tracks with different sustaining instruments\n",
    "track_name = available_tracks[0]  # Use first track\n",
    "\n",
    "# Try different instruments to hear note durations clearly:\n",
    "violin_path = generator.generate_single_track_with_sustaining_instrument(track_name, length=300, instrument=\"strings\")\n",
    "cello_path = generator.generate_single_track_with_sustaining_instrument(track_name, length=300, instrument=\"cello\") \n",
    "flute_path = generator.generate_single_track_with_sustaining_instrument(track_name, length=300, instrument=\"flute\")\n",
    "organ_path = generator.generate_single_track_with_sustaining_instrument(track_name, length=300, instrument=\"organ\")\n",
    "\n",
    "# Open one in GarageBand\n",
    "import subprocess\n",
    "subprocess.run([\"open\", \"-a\", \"GarageBand\", str(organ_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78b6abf-e734-42ba-9bfe-730ef13415a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-27T05:39:44.546448Z",
     "iopub.status.busy": "2025-06-27T05:39:44.546114Z",
     "iopub.status.idle": "2025-06-27T05:39:44.682337Z",
     "shell.execute_reply": "2025-06-27T05:39:44.682078Z",
     "shell.execute_reply.started": "2025-06-27T05:39:44.546431Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎼 Beethoven analysis results:\n",
      "\n",
      "📊 Beethoven file has 17 tracks\n",
      "Track 0: 0 note_ons, 0 note_offs\n",
      "Track 1: 404 note_ons, 404 note_offs\n",
      "Track 2: 420 note_ons, 420 note_offs\n",
      "Track 3: 436 note_ons, 436 note_offs\n",
      "Track 4: 538 note_ons, 538 note_offs\n",
      "Track 5: 203 note_ons, 203 note_offs\n",
      "Track 6: 125 note_ons, 125 note_offs\n",
      "Track 7: 86 note_ons, 86 note_offs\n",
      "Track 8: 884 note_ons, 884 note_offs\n",
      "Track 9: 738 note_ons, 738 note_offs\n",
      "Track 10: 775 note_ons, 775 note_offs\n",
      "Track 11: 154 note_ons, 154 note_offs\n",
      "Track 12: 1146 note_ons, 1146 note_offs\n",
      "Track 13: 0 note_ons, 0 note_offs\n",
      "Track 14: 0 note_ons, 0 note_offs\n",
      "Track 15: 0 note_ons, 0 note_offs\n",
      "Track 16: 0 note_ons, 0 note_offs\n",
      "\n",
      "🔍 Checking for rests in Beethoven analysis:\n",
      "track_0: has 'rest'? True, total states: 19\n",
      "  Rest transitions: {'rest': 0.3002481389578164, '81': 0.09925558312655088, '88': 0.1315136476426799, '76': 0.03970223325062035, '90': 0.01240694789081886, '91': 0.009925558312655087, '79': 0.017369727047146403, '83': 0.08684863523573201, '78': 0.019851116625310174, '80': 0.02729528535980149, '93': 0.004962779156327543, '92': 0.0024813895781637717, '85': 0.022332506203473945, '89': 0.03722084367245657, '84': 0.07692307692307693, '86': 0.09181141439205956, '87': 0.01240694789081886, '74': 0.004962779156327543, '72': 0.0024813895781637717}\n",
      "track_1: has 'rest'? True, total states: 21\n",
      "  Rest transitions: {'rest': 0.27817745803357313, '79': 0.03117505995203837, '75': 0.011990407673860911, '78': 0.03836930455635491, '81': 0.04316546762589928, '76': 0.17266187050359713, '72': 0.08633093525179857, '67': 0.009592326139088728, '83': 0.03357314148681055, '66': 0.002398081534772182, '68': 0.007194244604316547, '69': 0.0407673860911271, '80': 0.03357314148681055, '85': 0.002398081534772182, '71': 0.05515587529976019, '70': 0.004796163069544364, '77': 0.03597122302158273, '74': 0.09352517985611511, '73': 0.016786570743405275, '84': 0.002398081534772182}\n",
      "track_2: has 'rest'? True, total states: 22\n",
      "  Rest transitions: {'rest': 0.3741339491916859, '64': 0.03002309468822171, '76': 0.11316397228637413, '78': 0.03002309468822171, '67': 0.018475750577367205, '79': 0.006928406466512702, '81': 0.03926096997690531, '83': 0.004618937644341801, '71': 0.06466512702078522, '66': 0.03002309468822171, '80': 0.013856812933025405, '68': 0.025404157043879907, '69': 0.09468822170900693, '74': 0.057736720554272515, '73': 0.02771362586605081, '61': 0.004618937644341801, '59': 0.004618937644341801, '62': 0.004618937644341801, '75': 0.009237875288683603, '70': 0.006928406466512702, '72': 0.03695150115473441, '77': 0.0023094688221709007}\n",
      "track_3: has 'rest'? True, total states: 21\n",
      "  Rest transitions: {'rest': 0.3408239700374532, '60': 0.0749063670411985, '66': 0.0018726591760299626, '62': 0.08239700374531835, '64': 0.09737827715355805, '57': 0.09550561797752809, '52': 0.04868913857677903, '54': 0.031835205992509365, '55': 0.0149812734082397, '67': 0.00749063670411985, '59': 0.08614232209737828, '56': 0.024344569288389514, '61': 0.0299625468164794, '47': 0.0018726591760299626, '49': 0.003745318352059925, '58': 0.011235955056179775, '53': 0.0018726591760299626, '65': 0.02247191011235955, '63': 0.00749063670411985, '50': 0.0018726591760299626, '45': 0.013108614232209739}\n",
      "track_4: has 'rest'? True, total states: 11\n",
      "  Rest transitions: {'rest': 0.271356783919598, '52': 0.10552763819095477, '64': 0.31155778894472363, '66': 0.06532663316582915, '67': 0.11557788944723618, '69': 0.06030150753768844, '71': 0.020100502512562814, '68': 0.02512562814070352, '59': 0.010050251256281407, '63': 0.010050251256281407, '61': 0.005025125628140704}\n",
      "track_5: has 'rest'? True, total states: 5\n",
      "  Rest transitions: {'64': 0.3170731707317073, 'rest': 0.3333333333333333, '57': 0.21951219512195122, '45': 0.11382113821138211, '66': 0.016260162601626018}\n",
      "track_6: has 'rest'? True, total states: 4\n",
      "  Rest transitions: {'52': 0.47058823529411764, '45': 0.4588235294117647, '51': 0.07058823529411765}\n",
      "track_7: has 'rest'? True, total states: 30\n",
      "  Rest transitions: {'76': 0.12004530011325028, '78': 0.020385050962627407, '79': 0.030577576443941108, '81': 0.028312570781426953, '83': 0.01925254813137033, '80': 0.011325028312570781, 'rest': 0.10192525481313704, '84': 0.015855039637599093, '86': 0.013590033975084938, '72': 0.05096262740656852, '75': 0.0056625141562853904, '74': 0.053227633069082674, '77': 0.01245753114382786, '87': 0.0022650056625141564, '85': 0.0033975084937712344, '88': 0.021517553793884484, '69': 0.08493771234428087, '71': 0.0928652321630804, '73': 0.04756511891279728, '64': 0.07361268403171008, '61': 0.006795016987542469, '62': 0.030577576443941108, '66': 0.03284258210645526, '59': 0.0056625141562853904, '68': 0.03397508493771234, '67': 0.044167610419026046, '70': 0.010192525481313703, '65': 0.013590033975084938, '60': 0.011325028312570781, '55': 0.0011325028312570782}\n",
      "track_8: has 'rest'? True, total states: 28\n",
      "  Rest transitions: {'64': 0.08288043478260869, '66': 0.020380434782608696, '67': 0.025815217391304348, '69': 0.03940217391304348, '71': 0.051630434782608696, '68': 0.01358695652173913, 'rest': 0.2758152173913043, '72': 0.04755434782608696, '74': 0.042119565217391304, '75': 0.009510869565217392, '76': 0.03940217391304348, '77': 0.01358695652173913, '73': 0.009510869565217392, '60': 0.025815217391304348, '62': 0.03260869565217391, '83': 0.006793478260869565, '59': 0.04891304347826087, '57': 0.059782608695652176, '56': 0.025815217391304348, '55': 0.019021739130434784, '61': 0.020380434782608696, '63': 0.001358695652173913, '65': 0.029891304347826088, '78': 0.014945652173913044, '80': 0.010869565217391304, '81': 0.017663043478260868, '79': 0.01358695652173913, '84': 0.001358695652173913}\n",
      "track_9: has 'rest'? True, total states: 26\n",
      "  Rest transitions: {'52': 0.13601036269430053, 'rest': 0.19041450777202074, '50': 0.022020725388601035, '55': 0.046632124352331605, '57': 0.08419689119170984, '59': 0.09585492227979274, '54': 0.027202072538860103, '56': 0.03367875647668394, '60': 0.09326424870466321, '62': 0.06994818652849741, '63': 0.009067357512953367, '64': 0.06476683937823834, '65': 0.0038860103626943004, '61': 0.025906735751295335, '48': 0.010362694300518135, '47': 0.0025906735751295338, '45': 0.0025906735751295338, '71': 0.007772020725388601, '69': 0.011658031088082901, '49': 0.0038860103626943004, '66': 0.02072538860103627, '53': 0.011658031088082901, '67': 0.012953367875647668, '68': 0.0051813471502590676, '58': 0.006476683937823834, '72': 0.0012953367875647669}\n",
      "track_10: has 'rest'? True, total states: 19\n",
      "  Rest transitions: {'48': 0.1503267973856209, '47': 0.16993464052287582, '45': 0.1568627450980392, '52': 0.058823529411764705, '51': 0.026143790849673203, '50': 0.0392156862745098, '49': 0.013071895424836602, '57': 0.05228758169934641, '60': 0.058823529411764705, '44': 0.026143790849673203, '56': 0.0392156862745098, '59': 0.06535947712418301, '40': 0.032679738562091505, '43': 0.026143790849673203, '55': 0.026143790849673203, '62': 0.0196078431372549, '36': 0.032679738562091505, '64': 0.006535947712418301}\n",
      "track_11: has 'rest'? True, total states: 35\n",
      "  Rest transitions: {'rest': 0.40730837789661317, '33': 0.06951871657754011, '45': 0.1051693404634581, '32': 0.015151515151515152, '44': 0.0106951871657754, '28': 0.027629233511586453, '40': 0.040998217468805706, '43': 0.022281639928698752, '31': 0.01693404634581105, '48': 0.02406417112299465, '47': 0.025846702317290554, '36': 0.017825311942959002, '35': 0.011586452762923352, '30': 0.006238859180035651, '57': 0.04188948306595366, '59': 0.008912655971479501, '64': 0.008021390374331552, '52': 0.026737967914438502, '37': 0.00267379679144385, '61': 0.006238859180035651, '49': 0.008912655971479501, '38': 0.020499108734402853, '50': 0.023172905525846704, '62': 0.008021390374331552, '41': 0.006238859180035651, '53': 0.00267379679144385, '60': 0.012477718360071301, '42': 0.0071301247771836, '55': 0.008021390374331552, '54': 0.0035650623885918, '51': 0.00089126559714795, '56': 0.0017825311942959, '65': 0.00089126559714795}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the Beethoven file\n",
    "beet_results = generator.analyze_midi_file(Path(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/beet.mid\"))\n",
    "print(\"🎼 Beethoven analysis results:\")\n",
    "#print(beet_results)\n",
    "\n",
    "# Check track structure\n",
    "import mido\n",
    "beet_file = mido.MidiFile(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/beet.mid\")\n",
    "print(f\"\\n📊 Beethoven file has {len(beet_file.tracks)} tracks\")\n",
    "\n",
    "for track_num, track in enumerate(beet_file.tracks):\n",
    "    note_on_count = sum(1 for msg in track if msg.type == 'note_on' and msg.velocity > 0)\n",
    "    note_off_count = sum(1 for msg in track if msg.type in ['note_off', 'note_on'] and msg.velocity == 0)\n",
    "    print(f\"Track {track_num}: {note_on_count} note_ons, {note_off_count} note_offs\")\n",
    "\n",
    "# Check content chains for 'rest' states\n",
    "print(f\"\\n🔍 Checking for rests in Beethoven analysis:\")\n",
    "for track_name, chain in generator.content_chains.items():\n",
    "    has_rest = 'rest' in chain.transitions\n",
    "    states = list(chain.transitions.keys())\n",
    "    print(f\"{track_name}: has 'rest'? {has_rest}, total states: {len(states)}\")\n",
    "    if has_rest:\n",
    "        print(f\"  Rest transitions: {chain.transitions['rest']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3730b3-651f-49ff-9cb4-5682e5f77654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac7158-b135-490d-a88f-70ddbecf68de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ab841-dc2c-4e82-b466-a08f2e5f68fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e239223-0375-49b9-b6cb-346c8766882f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd1d6d-bba1-48ad-9f6f-17811e3ef42a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
