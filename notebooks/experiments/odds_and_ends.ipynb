{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3053df5-8838-4b30-a7e2-d91a319274f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's check what's actually being generated\n",
    "print(\"🔍 Debugging single track generation:\")\n",
    "print(f\"Track name being used: {track_name}\")\n",
    "\n",
    "# Generate one track and examine it\n",
    "single_track = generator.generate_composition(track_name, length=30)\n",
    "print(f\"Generated track has: {len(single_track.notes)} notes, {len(single_track.rests)} rests\")\n",
    "\n",
    "# Check if the save method exists\n",
    "if hasattr(generator, 'save_single_track_with_sustaining_instrument'):\n",
    "    print(\"✅ Single track save method exists\")\n",
    "else:\n",
    "    print(\"❌ Single track save method missing - you need to add it to your class\")\n",
    "\n",
    "# Test with a simple save to see track structure\n",
    "test_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/debug_single_track.mid\")\n",
    "generator.save_single_track_with_sustaining_instrument(single_track, test_path, \"cello\")\n",
    "\n",
    "# Let's examine the MIDI file structure\n",
    "import mido\n",
    "debug_file = mido.MidiFile(test_path)\n",
    "print(f\"\\n📊 MIDI file analysis:\")\n",
    "print(f\"Number of tracks in file: {len(debug_file.tracks)}\")\n",
    "print(f\"MIDI file type: {debug_file.type}\")\n",
    "\n",
    "for i, track in enumerate(debug_file.tracks):\n",
    "    note_count = sum(1 for msg in track if msg.type == 'note_on' and msg.velocity > 0)\n",
    "    print(f\"Track {i}: {note_count} note_on messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdedb3b-e4ef-4a8a-b901-4bd918e45ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh single-track test file with a unique name\n",
    "fresh_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/SINGLE_TRACK_TEST.mid\")\n",
    "generator.save_single_track_with_sustaining_instrument(single_track, fresh_path, \"cello\")\n",
    "\n",
    "# Verify it's single track\n",
    "import mido\n",
    "test_file = mido.MidiFile(fresh_path)\n",
    "print(f\"✅ Confirmed: {len(test_file.tracks)} track(s) in {fresh_path.name}\")\n",
    "\n",
    "# Close any open GarageBand files first, then open this specific file\n",
    "import subprocess\n",
    "subprocess.run([\"open\", \"-a\", \"GarageBand\", str(fresh_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a4c05-6bea-41c8-9632-4ab0329aa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug why no rests are being generated\n",
    "print(\"🔍 Debugging rest generation:\")\n",
    "\n",
    "# Check what's in the content chain (should have both notes and 'rest')\n",
    "track_name = available_tracks[0]\n",
    "content_chain = generator.content_chains[track_name]\n",
    "\n",
    "print(f\"Content chain states: {list(content_chain.transitions.keys())}\")\n",
    "print(f\"Content chain has 'rest'? {'rest' in content_chain.transitions}\")\n",
    "\n",
    "# Check some transition probabilities\n",
    "for state, transitions in list(content_chain.transitions.items())[:3]:\n",
    "    print(f\"From '{state}': {transitions}\")\n",
    "\n",
    "# Also check the original track analysis\n",
    "print(f\"\\nOriginal analysis showed: {results[track_name]['rests']} rests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e084c-094b-40c2-ba31-9949da211272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually trace through the MIDI file to see where rests should be detected\n",
    "import mido\n",
    "\n",
    "bach_file = mido.MidiFile(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/bach.mid\")\n",
    "\n",
    "# Analyze track 0 step by step\n",
    "track = bach_file.tracks[0]\n",
    "print(\"🔍 Manual rest detection analysis:\")\n",
    "\n",
    "current_time = 0.0\n",
    "active_notes = {}  # note -> start_time\n",
    "last_note_end = 0.0\n",
    "rest_count = 0\n",
    "\n",
    "print(\"First 20 MIDI messages:\")\n",
    "for i, message in enumerate(track):\n",
    "    current_time += message.time * (500000 / 1000000) / 480  # Convert ticks to seconds roughly\n",
    "    \n",
    "    if message.type == 'note_on' and message.velocity > 0:\n",
    "        # Note starts\n",
    "        print(f\"{i}: Note ON  {message.note} at time {current_time:.3f}\")\n",
    "        \n",
    "        # Check if there's a gap since last note ended (= rest)\n",
    "        if current_time > last_note_end and last_note_end > 0:\n",
    "            rest_duration = current_time - last_note_end\n",
    "            print(f\"   🎵 REST DETECTED: {rest_duration:.3f} seconds\")\n",
    "            rest_count += 1\n",
    "        \n",
    "        active_notes[message.note] = current_time\n",
    "        \n",
    "    elif message.type in ['note_off', 'note_on'] and message.velocity == 0:\n",
    "        # Note ends\n",
    "        if message.note in active_notes:\n",
    "            start_time = active_notes.pop(message.note)\n",
    "            duration = current_time - start_time\n",
    "            print(f\"{i}: Note OFF {message.note} at time {current_time:.3f}, duration {duration:.3f}\")\n",
    "            last_note_end = max(last_note_end, current_time)\n",
    "    \n",
    "    if i >= 20:  # Just analyze first 20 messages\n",
    "        break\n",
    "\n",
    "print(f\"\\n📊 Manual analysis found {rest_count} rests in first 20 messages\")\n",
    "print(f\"Our algorithm found: {results['track_0']['rests']} rests in entire track\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57300b5-edbf-4b9a-8695-8f3cc1d75ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what types of messages are in the MIDI file\n",
    "import mido\n",
    "\n",
    "bach_file = mido.MidiFile(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/bach.mid\")\n",
    "track = bach_file.tracks[0]\n",
    "\n",
    "print(\"🔍 All message types in first 30 messages:\")\n",
    "current_time = 0\n",
    "for i, message in enumerate(track):\n",
    "    current_time += message.time\n",
    "    print(f\"{i:2d}: {message.type:15} | time:{message.time:4d} | cumulative:{current_time:6d} | {message}\")\n",
    "    \n",
    "    if i >= 30:\n",
    "        break\n",
    "\n",
    "print(f\"\\n📊 Message type summary:\")\n",
    "message_types = {}\n",
    "note_on_count = 0\n",
    "note_off_count = 0\n",
    "\n",
    "for message in track:\n",
    "    msg_type = message.type\n",
    "    message_types[msg_type] = message_types.get(msg_type, 0) + 1\n",
    "    \n",
    "    if message.type == 'note_on' and message.velocity > 0:\n",
    "        note_on_count += 1\n",
    "    elif message.type in ['note_off', 'note_on'] and message.velocity == 0:\n",
    "        note_off_count += 1\n",
    "\n",
    "for msg_type, count in sorted(message_types.items()):\n",
    "    print(f\"  {msg_type}: {count}\")\n",
    "\n",
    "print(f\"\\nActual note events:\")\n",
    "print(f\"  Note ONs: {note_on_count}\")\n",
    "print(f\"  Note OFFs: {note_off_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40243907-a513-4bfd-8976-4d42870dc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check all tracks in the Bach file\n",
    "bach_file = mido.MidiFile(\"/Users/abraxas3d/organ_donor/data/midi_files/songs/bach.mid\")\n",
    "print(f\"🎼 Bach file has {len(bach_file.tracks)} tracks total\")\n",
    "\n",
    "for track_num, track in enumerate(bach_file.tracks):\n",
    "    note_on_count = 0\n",
    "    note_off_count = 0\n",
    "    message_count = len(track)\n",
    "    \n",
    "    for message in track:\n",
    "        if message.type == 'note_on' and message.velocity > 0:\n",
    "            note_on_count += 1\n",
    "        elif message.type in ['note_off', 'note_on'] and message.velocity == 0:\n",
    "            note_off_count += 1\n",
    "    \n",
    "    print(f\"Track {track_num}: {message_count} messages, {note_on_count} note_ons, {note_off_count} note_offs\")\n",
    "\n",
    "# Let's analyze a track that actually has notes\n",
    "for track_num, track in enumerate(bach_file.tracks):\n",
    "    if any(msg.type == 'note_on' and msg.velocity > 0 for msg in track):\n",
    "        print(f\"\\n🎵 Analyzing Track {track_num} (has notes):\")\n",
    "        \n",
    "        # Re-run our analysis on a track with actual notes\n",
    "        extractor = MidiEventExtractor()\n",
    "        analyzed_track = extractor.extract_track(track, bach_file.ticks_per_beat)\n",
    "        \n",
    "        print(f\"Found: {len(analyzed_track.notes)} notes, {len(analyzed_track.rests)} rests\")\n",
    "        \n",
    "        # Show first few notes and their timing\n",
    "        for i, note in enumerate(analyzed_track.notes[:5]):\n",
    "            print(f\"  Note {i}: pitch {note.pitch}, start {note.start_time:.3f}, duration {note.duration:.3f}\")\n",
    "        \n",
    "        for i, rest in enumerate(analyzed_track.rests[:5]):\n",
    "            print(f\"  Rest {i}: start {rest.start_time:.3f}, duration {rest.duration:.3f}\")\n",
    "        \n",
    "        break  # Just analyze the first track with notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503c337-da94-478c-ab5d-d6d220121106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if ALL notes are perfectly connected\n",
    "track1_notes = analyzed_track.notes\n",
    "\n",
    "gaps = []\n",
    "overlaps = []\n",
    "perfect_connections = 0\n",
    "\n",
    "for i in range(len(track1_notes) - 1):\n",
    "    current_end = track1_notes[i].start_time + track1_notes[i].duration\n",
    "    next_start = track1_notes[i + 1].start_time\n",
    "    \n",
    "    gap = next_start - current_end\n",
    "    \n",
    "    if abs(gap) < 0.001:  # Perfectly connected (within 1ms)\n",
    "        perfect_connections += 1\n",
    "    elif gap > 0:  # Actual gap (rest)\n",
    "        gaps.append(gap)\n",
    "    else:  # Overlap\n",
    "        overlaps.append(abs(gap))\n",
    "\n",
    "print(f\"📊 Note connection analysis:\")\n",
    "print(f\"Perfect connections: {perfect_connections}\")\n",
    "print(f\"Actual gaps (rests): {len(gaps)}\")\n",
    "print(f\"Overlaps: {len(overlaps)}\")\n",
    "\n",
    "if gaps:\n",
    "    print(f\"Gap sizes: min={min(gaps):.3f}, max={max(gaps):.3f}, avg={sum(gaps)/len(gaps):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eeff41-3055-4eae-b2f7-3c4ee8c38cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for 'rest' states in the Beethoven content chains\n",
    "print(\"🔍 Checking Beethoven content chains for rests:\")\n",
    "for track_name, chain in generator.content_chains.items():\n",
    "    has_rest = 'rest' in chain.transitions\n",
    "    total_states = len(chain.transitions)\n",
    "    print(f\"{track_name}: has 'rest'? {has_rest}, total states: {total_states}\")\n",
    "    \n",
    "    if has_rest:\n",
    "        rest_transitions = chain.transitions['rest']\n",
    "        print(f\"  From 'rest' goes to: {list(rest_transitions.keys())[:5]}...\")  # Show first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb0aa4-d939-496b-910c-4c834b9ba64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate composition from Beethoven with rests\n",
    "available_tracks = list(generator.note_chains.keys())\n",
    "print(f\"Available Beethoven tracks: {available_tracks}\")\n",
    "\n",
    "# Use track_0 (which has lots of rests)\n",
    "beethoven_track = generator.generate_composition('track_0', length=300)\n",
    "print(f\"Generated Beethoven-style: {len(beethoven_track.notes)} notes, {len(beethoven_track.rests)} rests\")\n",
    "\n",
    "# Save with sustaining instrument\n",
    "beet_path = Path(\"/Users/abraxas3d/organ_donor/data/generated/beethoven_with_rests.mid\")\n",
    "generator.save_single_track_with_sustaining_instrument(beethoven_track, beet_path, \"cello\")\n",
    "\n",
    "print(f\"🎵 Saved Beethoven-inspired composition with natural rests!\")\n",
    "print(f\"This should have the breathing patterns of the original!\")\n",
    "\n",
    "# Open in GarageBand  \n",
    "import subprocess\n",
    "subprocess.run([\"open\", \"-a\", \"GarageBand\", str(beet_path)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
